{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets , transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarin_data = datasets.MNIST(root=\"data\",train=True,transform=transforms.ToTensor(),download=True,target_transform=None)\n",
    "test_data = datasets.MNIST(root=\"data\",train=False,transform=transforms.ToTensor(),download=True,target_transform=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 - zero',\n",
       " '1 - one',\n",
       " '2 - two',\n",
       " '3 - three',\n",
       " '4 - four',\n",
       " '5 - five',\n",
       " '6 - six',\n",
       " '7 - seven',\n",
       " '8 - eight',\n",
       " '9 - nine']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = test_data.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0 - zero': 0,\n",
       " '1 - one': 1,\n",
       " '2 - two': 2,\n",
       " '3 - three': 3,\n",
       " '4 - four': 4,\n",
       " '5 - five': 5,\n",
       " '6 - six': 6,\n",
       " '7 - seven': 7,\n",
       " '8 - eight': 8,\n",
       " '9 - nine': 9}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image,lable = tarin_data[0]\n",
    "\n",
    "image , lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(image.squeeze())\n",
    "plt.title(lable);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(dataset=tarin_data,\n",
    "                              batch_size = BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                              batch_size = BATCH_SIZE,\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_batch , train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape,train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "class MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MNIST().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=model.parameters(),\n",
    "                            lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNIST(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model:nn.Module,\n",
    "               data_loader:torch.utils.data.DataLoader,\n",
    "               loss_fn:nn.Module,\n",
    "               optimizer:torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device:torch.device = device):\n",
    "    \n",
    "    train_loss , train_acc = 0,0\n",
    "\n",
    "    for batch,(X,Y) in enumerate(data_loader):\n",
    "\n",
    "        X,Y = X.to(device),Y.to(device)\n",
    "\n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = loss_fn(y_pred,Y)\n",
    "\n",
    "        train_loss += loss\n",
    "\n",
    "        train_acc += accuracy_fn(Y,y_pred.argmax(dim=1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model:nn.Module,\n",
    "              data_loader:torch.utils.data.DataLoader,\n",
    "              loss_fn:nn.Module,\n",
    "              accuracy_fn,\n",
    "              device:torch.device = device):\n",
    "    \n",
    "    test_loss , test_acc = 0,0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X ,Y in data_loader:\n",
    "            X,Y = X.to(device),Y.to(device)\n",
    "\n",
    "            test_pred = model(X)\n",
    "\n",
    "            loss = loss_fn(test_pred,Y)\n",
    "\n",
    "            test_loss += loss\n",
    "\n",
    "            test_acc += accuracy_fn(Y,test_pred.argmax(dim=1))\n",
    "\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "--------\n",
      "Train loss: 1.46373 | Train acc: 70.91%\n",
      "Test loss: 0.69866 | Test acc: 82.68%\n",
      "\n",
      "Epoch: 1\n",
      "--------\n",
      "Train loss: 0.54020 | Train acc: 85.32%\n",
      "Test loss: 0.41391 | Test acc: 88.10%\n",
      "\n",
      "Epoch: 2\n",
      "--------\n",
      "Train loss: 0.39848 | Train acc: 88.40%\n",
      "Test loss: 0.33716 | Test acc: 90.25%\n",
      "\n",
      "Epoch: 3\n",
      "--------\n",
      "Train loss: 0.33937 | Train acc: 90.13%\n",
      "Test loss: 0.29404 | Test acc: 91.32%\n",
      "\n",
      "Epoch: 4\n",
      "--------\n",
      "Train loss: 0.29839 | Train acc: 91.26%\n",
      "Test loss: 0.25719 | Test acc: 92.26%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    print(f\"Epoch: {epoch}\\n--------\")\n",
    "\n",
    "    train_step(model=model,\n",
    "               data_loader=train_dataloader,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               accuracy_fn=accuracy_fn,\n",
    "               device=device)\n",
    "    \n",
    "\n",
    "    test_step(model=model,\n",
    "              data_loader=test_dataloader,\n",
    "              loss_fn=loss_fn,\n",
    "              accuracy_fn=accuracy_fn,\n",
    "              device=device)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 192.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model_name': 'MNIST',\n",
       " 'model_loss': 0.25719153881073,\n",
       " 'model_acc': 92.2623801916933}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def eval_model_gpu(model:torch.nn.Module,\n",
    "               data_loader:torch.utils.data.DataLoader,\n",
    "               loss_fn:torch.nn.Module,\n",
    "               accuracy_fn):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting on data_loader.\"\"\"\n",
    "    loss,acc = 0,0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X,Y in tqdm(data_loader):\n",
    "            # Make prediction\n",
    "            X,Y = X.to(device),Y.to(device)\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Accumulate the loss and acc values per batch\n",
    "            loss += loss_fn(y_pred,Y)\n",
    "\n",
    "            acc += accuracy_fn(Y,y_pred.argmax(dim=1))\n",
    "            \n",
    "        \n",
    "        # Scale loss and acc to find the average loss/acc per batch\n",
    "\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    return {\"Model_name\": model.__class__.__name__,\n",
    "            \"model_loss\":loss.item(),\n",
    "            \"model_acc\":acc}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_0_results = eval_model_gpu(model=model,\n",
    "                             data_loader=test_dataloader,\n",
    "                             loss_fn=loss_fn,\n",
    "                             accuracy_fn=accuracy_fn)\n",
    "\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
